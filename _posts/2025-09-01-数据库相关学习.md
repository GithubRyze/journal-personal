---
title: 数据库学习
author: 刘Sir
date: 2025-08-28 10:10:00 +0800
categories: [技术]
tags: [数据库]
render_with_liquid: false
---

## 数据库事务
事务的特性 ACID：
- Atomicity (原子性): 一个事务要么全部执行成功，要么全部不执行（回滚），不会只执行一部分。数据库使用 日志（Redo/Undo Log） 来回滚未完成的操作。
- Consistency（一致性）：事务执行前后，数据库必须处于合法的状态，即满足所有约束（主键、外键、唯一约束、触发器等）。依赖数据库的约束和触发器来保证一致性。
- Isolation（隔离性）：并发事务之间互不干扰，每个事务的中间状态对其他事务不可见。这里有隔离级别：
```
READ UNCOMMITTED（未提交读） → 可能出现脏读
READ COMMITTED（提交读） → 防脏读，但可能不可重复读
REPEATABLE READ（可重复读） → 防脏读和不可重复读，但可能幻读
SERIALIZABLE（串行化） → 最严格，完全避免并发问题
```
- Durability (持久性):事务一旦提交，对数据库的修改就是永久的，即使系统崩溃也不会丢失. 使用 事务日志（Redo Log） 写入磁盘。

其中 Isolation（隔离性） 是可以通过配置，其他三个是数据库不可选，必须支持的。事物的隔离级别需要再单独拿出来理解。但是在这个之前需要理解三个读的概念：
- 脏读：事务读取的数据和数据库中的内容不一样
- 重复读：在同一个事务中多次读取同一条记录，结果都是一样的。因为其他事物也可能会修改数据
- 幻读：在同一事务中对范围查询多次执行，可能每次得到的记录条数不同，因为其他事务插入了新记录或删除了记录


READ UNCOMMITTED（未提交读）：即数据库事物还未提交，但是已经可被 select 到。但是这个事务很可能会回滚，因此导致 select 的数据和最终回滚后的数据不一致，叫脏读。
READ COMMITTED（提交读）：数据库事务提交后，才能被 select 到。但是不能保证**同一事务中多次读取同一记录，结果是一样的**（多次读数据不一致）因为其他事务可能修改了数据
REPEATABLE READ（可重复读）：数据库事务提交后，才能被 select 到，并且保证**同一事务中多次读取同一记录，结果是一样的** （即使其他事物修改了数据），但是可能幻读

| 数据库              | 默认隔离级别          | 说明                                           |
| ---------------- | --------------- | -------------------------------------------- |
| **MySQL InnoDB** | REPEATABLE READ | 避免不可重复读，支持多版本并发控制（MVCC），可防幻读（通过间隙锁 Gap Lock） |
| **PostgreSQL**   | READ COMMITTED  | 每次查询都只看到已提交的数据，不保证重复读                        |
| **Oracle**       | READ COMMITTED  | 类似 PostgreSQL，MVCC 实现，保证读取已提交数据              |
| **SQL Server**   | READ COMMITTED  | 默认会加行级锁，保证读取已提交数据                            |

## MySQL 中 CHAR 和 VARCHAR 的区别
char 是不可变的长度，字符长度固定，不足补空格（存储的字符少于声明长度，会用空格填充）。适用于：字符长度固定的字段，如身份证号、邮政编码、性别标识等。

varchar 声明时长度是最大值，实际存储多少字符就占多少空间。适用于：长度不固定的字段，如姓名、地址、备注等

## select ..... for update
会对符合条件的行加 **排它锁（X Lock）**，阻止其他事务对这些行进行修改（UPDATE、DELETE、SELECT … FOR UPDATE）。用于 悲观锁场景，确保事务中读取的数据在操作期间不被修改。

## 如果两个事务同时更新同一行，会发生什么？InnoDB 是如何保证安全的？
行锁 + 排队执行更新  + MVCC 支持高并发读取不阻塞

## B + 树
数据库中主键，联合索引，普通索引都是使用 B + 树的数据结构，其有以下特点：
- 多路平衡：每个节点可以有多个子节点（非二叉树），这样树的高度更低，减少磁盘 IO。
- 有序链表：叶子节点按顺序连接，方便范围查询和顺序扫描。
- 只在叶子节点存储数据（B+ 树），非叶子节点只存储索引键。

 索引类型 | 结构特点       | 支持查询类型  | 更新性能 | 适用场景       |
| ---- | ---------- | ------- | ---- | ---------- |
| B+ 树 | 多路平衡树，叶子链表 | 精确、范围   | 较好   | 主键、排序、范围查询 |
| 哈希   | 哈希表，桶定位    | 精确等值    | 极快   | 精确查找，内存表   |
| 位图   | 位向量        | 精确、组合条件 | 差    | 低基数列、统计分析  |

聚集索引：以主键创建的 b+ 树索引

非聚集索引：以主键以外的创建 b+ 树索引

区别：非聚集索引中的 b+ 树叶子节点不存储具体的数据，而是存储对应的主键，因此通过非主键索引查询数据，需要再回到主键索引（聚集索引）中来获取数据，这个过程叫回表查询（es 协调节点查询类似），因此在我看来非聚集索引为何这么做是为了平衡内存和速度，非聚集索引牺牲了速度但是换了更小的内存占用。

另外还有个一个索引覆盖的概念：查询所需的所有字段都可以从索引本身获取，无需访问表中的数据行（不需要回表）。这种情况可能更多见于联合字段所创建的索引，比如（name，性别，年龄）三个字段组合索引，那么在查询的时候索引本身就有这些信息，不需要在回表。在某种程度上可以提升查询效率，但是我感觉这里是用空间换时间。

## 当一个表有百万级数据，查询某个字段很慢，你会怎么排查和优化？
这种大部分是 select 没有走索引导致的，首先使用 explain 查询 sql 的执行计划。
- type：看是否全表扫描
- keys：看使用哪些索引
- rows：扫描的行数，越少越好
- extra： 是否有 Using index（覆盖索引）、Using filesort（排序）、Using temporary（临时表）

检查表和索引结构（分析 sql ）
- 是否有索引覆盖查询字段
- 索引是否被函数包裹或隐式转换（会导致索引失效）

查看表统计信息：ANALYZE TABLE table；统计信息不准可能导致优化器选择全表扫描

**排查思路：查看执行计划 → 看索引 → 分析 SQL → 优化索引或表**

**优化方式分为 索引优化 / SQL 优化 / 分表分区 / 缓存 四类**

## 分库分表
在数据量大的情况下，目前的很多应用都是基于分库分表的解决方案，比如 es 是分片，rocket mq 队列也是分库的思想，kafka 的分区思想都是上面分库和分表的的体现。分库：把数据划分到不同的数据库中，分表：把数据划分到不同的表中。按照业务也好，hash也好，或者时间/id 等范围划分，或者把表的字段拆开分库分表（垂直），这些都使存储和查询的业务带来更高的复杂性，入库需要判断进入那个库，特别是带来查询上的复杂度，因为需要聚合数据，分库要聚合，分表要 join，分片的方式还可能导致数据不平衡的问题等。在我的工作中很多时候我们上基于业务来进行分表，比如我们在 his 系统中就上把患者的账单分为 住院患者和门诊患者，住院患者的账单又分为 ffs，package 这种方式，基本上都可以满足业务的需求。

## 支持高入库，高查询
在如何支持高写入和高查询的场景，我们首先需要了解影响高写入和高查询的有哪些因素，大部分因素如下：
- 锁，程序的锁，数据库的锁，分布式锁等都会严重影响高并发
- 索引：这是影响查询效率的最大因素，设计一个高效的索引至关重要
- 硬件（磁盘/内存/cpu）：对于关系型数据其磁盘的读写速度对于数据库来说同样非常重要，因此配置高的服务器能大大的提高读写速度
- 数据大小：读写大的数据和读写小的数据，速度上也有很大的差距，可能一次不明显，但是累计可节省就非常可观了。  

那么针对以上这几点我们就可以分开看看有哪些策略可以帮助提高数据库的读写速度了。
### 锁
降低锁的竞争是我们第一步需要做的事情，降低锁竞争可以通过以下方式：
- 梳理业务，合理配置程序锁（java ReentrantLock mutex），分布式锁，尽量减低锁的粒度，比如：用户id 锁 ——》订单锁 等
- 分表/分库，减少数据库锁（行锁，页锁，表锁）的竞争
- 尽可能的使用批量入库的方式 （可以选择先写 mq，再批量入库）
- 避免事务中做复杂的业务操作，减少锁的占用时间
### 索引
索引是因此查询效率的关键，因此我们要提高索引使用：
- 配置合适的索引 (user_id, status, create_time)，对于热门查询可以配置覆盖索引，减少回表次数
- 主键（uuid，雪花算法）：自增ID会集中在索引末尾 → 写入集中 → 页锁竞争
- 尽可能的使用索引进行查询，避免全表扫描 （WHERE 条件模糊导致全表扫描 ）
### 硬件和数据大小
硬件这里就不说了内存，cpu，磁盘都使用好点的配置。至于数据的大小
- 使用更小的数据类型，比如（int/date 比 CHAR/VARCHAR 占用少），状态、类型字段尽量使用枚举或小整型
- 分表/分库，单表/单库的数据量大，分开后不仅减少锁竞争，而且更小的数据量可以提高查询效率
- 可垂直分表，把热点字段（userid，amount，status）等放到额外表中。

### 其他 
无非是利用缓存了，利用 redis 等缓存一些数据，查询先走缓存，因为是内存型的数据库 qps 可以非常的高，再一个是利用 mq 的方式，进行削峰填谷，这样都可以避免让数据库承受过大的压力，从而影响数据库的表现



## 数据库范式
哪些列参与了主键，就叫主属性；没参与的就是非主属性
- 第一范式（1NF）：每一列都是不可再分的原子值，每一行都是唯一的，如：不能 电话字段曾在两个号码
- 第二范式（2NF）：满足 1NF，要求表中每个非主属性都必须完全依赖于主键，不能只依赖主键的一部分。
- 第三范式（3NF）：满足 2NF，并且非主属性不依赖于其他非主属性（没有传递依赖）

实际的代码中我们需要平衡程序的数据结构和数据库的映射，可读性，查询效率等方面，因此我不会完全遵循这个规范，因为我认为上面这些点比数据库的 3 个范式对于应用来说更重要

## MySQL 主从复制
主库执行更新（update/delete/insert）操作会记录到 binlog，从库通过 tcp 连接后，读取主库的 binlog 写入从库中的 relay log，从库的从 relay log 读取和执行 sql，做到和主库的数据一致

- 异步复制，主库执行事务提交后立即返回给客户端，不等待从库确认，从库可能丢数据，但是主效率高
- 半同步：主库提交事务时，会等待至少一个从库确认收到 binlog，但不等待从库执行完成。从库丢数据小，主效率降低