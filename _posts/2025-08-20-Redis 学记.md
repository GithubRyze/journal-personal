---
title: Redis 学记
author: 刘Sir
date: 2025-08-14 10:10:00 +0800
categories: [技术]
tags: [redis]
render_with_liquid: false
---

## 基本知识
在 Redis 中，每个命令的执行都是原子的。这是因为 Redis 是单线程处理命令的（核心网络模型是单 Reactor 单线程，严格来说执行命令的工作线程是单线程）。服务器会从网络套接字中读取一个完整的命令，执行它，然后将结果返回给客户端。在执行这个命令的过程中，不会被其他命令打断
- redis 命令是天生原子操作
- redis 支持事物 - 将多个命令打包，保证它们按顺序执行，且不会被其他命令打断。
```
// 使用 Watch 监听键，如果 age 在事务执行前被修改，则事务会失败
txnFn := func(tx *redis.Tx) error {
    currentAge, err := tx.HGet(ctx, "user:1001", "age").Int()
    if err != nil nil {
        return err
    }
    newAge := currentAge + 1
    // 在事务中执行命令
    _, err = tx.TxPipelined(ctx, func(pipe redis.Pipeliner) error {
        pipe.HSet(ctx, "user:1001", "age", newAge)
        return nil
    })
    return err
}
// 重试机制
err := rdb.Watch(ctx, txnFn, "user:1001")
```
- 支持 Lua 脚本 (Lua Scripting)
```
// 使用 Lua 脚本原子性地检查并设置年龄
script := `
local current = redis.call('HGET', KEYS[1], 'age')
current = tonumber(current)
local new = current + 1
return redis.call('HSET', KEYS[1], 'age', new)
`
sha, err := rdb.ScriptLoad(ctx, script).Result()
if err != nil nil {
    log.Fatal(err)
}
// 执行脚本
rdb.EvalSha(ctx, sha, []string{"user:1001"})
```
按照官方文档介绍 redis 可以做以下用途：
- 内存数据库 in-memeory
- 文档数据库 document database
- 向量数据库 vector database
- RAG 用途

对比其他的内存型数据库，有以下这些特点：
- 支持持久化
- 丰富的数据类型，并且支持原子操作

### 持久化方式 
rdb: 在特定时间点，生成整个数据库的一个快照（Snapshot）
aof: 记录每一次写操作命令，以日志的形式追加到文件末尾。

#### rdb
当满足持久化条件后，redis 会 fork 一个子进程来执行持久化的操作。执行过程大致如下：
1. 触发时机：当满足 save 配置的条件（如900秒内1个key变化）或接收到 SAVE/BGSAVE 命令时，父进程决定创建 RDB 快照
2. 创建子进程：父进程通过 fork() 系统调用创建一个子进程，fork() 的作用是创建当前进程的一个完全相同副本
3. 子进程拥有父进程在调用 fork() 那一刻的完整内存数据副本 （此后不会再变了）
4. 生成 RDB 文件：子进程完全基于这个内存快照，序列化所有数据，并将其写入一个临时的 RDB 文件，完全独立的，无论多耗时，都不会影响父进程
5. 子进程完成写入后，用新的临时文件原子地替换掉旧的 RDB 文件，然后子进程退出
6. 父进程持续服务：在整个第3步到第5步期间，父进程一直在正常处理所有客户端的读写命令。它不会被子进程的 I/O（磁盘写入）或 CPU（序列化数据）操作所阻塞

copy-on-write：写时复制，在父进程复制一份新的内存页，在新的内存页上面修改，因此会导致内存上升。子进程的内存在 fork 的时候就可以理解成冻结了，不会在变。因此这里有个时间差可能会丢失数据

- sava 命令会阻塞父进程。Redis 主进程自己来执行生成和写入 RDB 文件的操作，在此期间无法处理任何命令
- bgsave 不阻塞父进程。通过 fork 子进程来完成所有工作

此过程中，子进程 fork 出处理 rdb 文件时基于 fork 的时间点，如果后面父进程继续修改数据，子进程不会同步，因此存在丢失数据的可能，因此引发了 aof 持久化模式。
#### aof
这个机制有类似于数据量的 binarylog，把所有写操作的命令（set，hset等）追加到日志文件中，重启的时候，通过读取 aof 文件来恢复数据。从内存到磁盘的策略可以配置化 appendfsync：
- always 每一条命令都 fsync 到磁盘
- everysec： 每多少秒 fsync 到磁盘
- no：系统决定
aof 日志文件随着写的数量会越越来大，因此会对文件的命令进行 merge 操作。常见的配置如下：
```
appendonly yes              # 开启 AOF
appendfilename "appendonly.aof"
appendfsync everysec        # 推荐配置，性能和安全性平衡
no-appendfsync-on-rewrite no # 是否在 rewrite 期间禁止 fsync
auto-aof-rewrite-percentage 100 # 当 AOF 文件大小增长超过上次 rewrite 的 100% 时触发
auto-aof-rewrite-min-size 64mb # AOF 文件最小 64MB 才能触发 rewrite

aof vs rdb

| 特性    | AOF       | RDB           |
| ----- | --------- | ------------- |
| 数据安全性 | 更高，丢失数据少  | 丢失数据多（依赖快照间隔） |
| 文件大小  | 较大        | 较小            |
| 恢复速度  | 慢（逐条回放）   | 快（直接读快照）      |
| 性能影响  | 较大（持续写磁盘） | 较小            |


```
## 数据类型
redis 有5种数据类型，string, hash, list, set(集合), zset（有序集合）

### string
二进制安全（编码无关的），最大支持 512 mb, 可以包含任何数据。，如图片和序列号对象。那么什么是二进制安全的呢？**一个二进制安全的函数（或系统）会将其输入（Input）纯粹当作一个原始的、无任何特殊含义的二进制数据流（即字节序列）来处理。它不会对数据内容做任何假设、解释或转换。**
- 非二进制安全 **系统会预定义一些“特殊字符”作为指令或分隔符，**如在 C 语言中，字符串以空字符（\0，ASCII 码为 0）作为结束符

因此客户端使用 redis-cli set name "hello world" 的时候会**按照 Redis 序列化协议（RESP）的规则，将您的命令和参数转换成一个字节序列（Byte Array）**

### hash 
hash是一个string类型的field和value的映射表（这个表才是理解的关键）。这里的使用需要和上面的 string 类型需要区分出来。我是这么理解的：
- string 和我们通常使用的 hashmap 是一样的
- hash 更像是 string（key） 下面的的 hashmap，数据结构类似是（key-hashmap），每个 key 可以存储 2 的 32次方 - 1 键值对（40多亿）。

使用释例
其中 user:1 是 string，然后 username redis.net.cn password redis.net.cn points 200 都是 hash 键值对。
```
redis 127.0.0.1:6379> HMSET user:1 username redis.net.cn password redis.net.cn points 200
OK
redis 127.0.0.1:6379> HGETALL user:1

```

如果我们需要存储一个对象数据我们可以有两个做法：
- string 存储，对象序列化成 json 字符，如 set user:1111  '{"Name":"Alice","Age":30,"Email":"alice@example.com"}'
- hash 存储，HSET user:1001 Name "Alice" Age "30" Email "alice@example.com"

从上可以看出，如果你需要对对象数据进行频繁的修改操作，string 必须每次都序列化完整的数据内容，而 hash 则可对单个字段进行修改。另外使用 hash 还有其他的以下的好处：
- 节省内存，Redis Hash 在内部使用 ziplist（元素少时）或 hashtable 编码，对于存储多个字段的对象，比一个完整的 JSON 字符串更节省内存
- 原子操作：对单个字段的读写是原子的 （string 需要先取再修改，如只是单操作也是原子的）

#### ziplist/hashtable 

### list
Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。
```
redis 127.0.0.1:6379> lpush redis.net.cn redis
(integer) 1
redis 127.0.0.1:6379> lpush redis.net.cn mongodb
(integer) 2
redis 127.0.0.1:6379> lpush redis.net.cn rabitmq
(integer) 3
```
可以用来做队列(先进先出)，栈（先进后出）
### set 集合 java hashset
Redis的Set是string类型的**无序集合。集合成员是唯一的**

，这就意味着集合中不能出现重复的数据。Redis 中 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。集合中最大的成员数为 2 的 32次方 - 1 (4294967295, 每个集合可存储40多亿个成员)

```
redis 127.0.0.1:6379> SADD test redis111
(integer) 1
redis 127.0.0.1:6379> SADD test redis222
(integer) 1
redis 127.0.0.1:6379> SADD test redis333
(integer) 1
redis 127.0.0.1:6379> SADD test redis333
(integer) 0
redis 127.0.0.1:6379> SMEMBERS test
 
1) "redis111"
2) "redis222"
3) "redis333"
```
可以用来做过滤，黑名单等操作。

### zset 有序集合
Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。有序集合的成员是唯一的,但分数(score)却可以重复。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员2 的 32次方 - 1 (4294967295, 每个集合可存储40多亿个成员)。
```
redis 127.0.0.1:6379> ZADD test 1 redis111
(integer) 1
redis 127.0.0.1:6379> ZADD test 2 redis222
(integer) 1
redis 127.0.0.1:6379> ZADD test 3 redis333
(integer) 1
redis 127.0.0.1:6379> ZRANGE test 0 10 WITHSCORES
 
1) "redis111"
2) "1"
3) "redis222"
4) "2"
5) "redis333"
6) "3"
```
对比 set 多一个用于排序的 score 字段。使用场景
- 这个可用来做数据排名场景，比如 top 多少这种。
- 速率限流策略，通过创建滑动窗口限制 api 请求速率

### vector sets 向量集合
专门用于高纬度向量数据类型的管理所设计的数据结构

```
> VADD points VALUES 2 1.0 1.0 pt:A
(integer) 1
> VADD points VALUES 2 -1.0 -1.0 pt:B
(integer) 1
```
这个数据结构主要是用于以下这些使用场景：
- 推荐系统：快速找到与用户兴趣向量最相似的商品或内容
- 图像识别与检索：存储图像特征向量，实现以图搜图或图像分类
- 机器学习和语义检索：用于文本语义搜索、聊天机器人、异常检测等6。例如在 RAG（检索增强生成）中，为 LLM 快速检索相关的上下文信息。缓存 AI 模型（如 LLM）的响应，当接收到语义相似的查询时，可直接返回缓存结果，减少对模型的调用

###  stream 流
此数据结构的实现是采用 append-only log 的方式，对比传统的 append-only log 方式它支持随机访问 o（1），并且支持更复杂的消费策略。在 stream 出现之前很多程序会采用 list， pub/sub 进行模拟消息队列（可能存在一些成本的考虑不需要专门的 mq 系统，或者并不需要复杂的 mq 场景）。因此 redis 通过支持 stream 的数据结构，扩展其在这方面的使用场景。因此 redis 可以作为系统轻量级的 mq 使用。比如以下使用场景：
- 事件溯源（例如，跟踪用户作、点击等）
- 传感器监控（例如，现场设备的读数）
- 通知（例如，将每个用户的通知记录存储在单独的流中）发布订阅 mq 模式。

文档中说 redis 会为每个 stream 中 entry 产生一个 id <millisecondsTime>-<sequenceNumber>（与时间关联的），如下：
```
> XADD race:france * rider Castilla speed 30.2 position 1 location_id 1
"1692632086370-0"
> XADD race:france * rider Norem speed 28.8 position 3 location_id 1
"1692632094485-0"
> XADD race:france * rider Prickett speed 29.7 position 2 location_id 1
"1692632102976-0"
```
因有此特点 redis 在单机的时候几乎不存在 id 重复（除非时间回退），另外在高可用集群中多个主节点的情况会存在此情况。因此最好的方式是由客户端产生 id 显示传递给 redis 是最佳。

radix trees：文档提到 stream 使用了这种数据结构核心优化是 "压缩" 。它将那些只有一个子节点的连续节点合并成一个节点，这个节点存储一整段字符串（而不再是一个字符）
```
        (root)
        /    \
     "app"    "banana"
     /   \
("le")   ("")
```
这种数据结构可以看出，抽取公共的前缀作为节点，而不是每个数据一个节点，能很好的利用内存空间。很多路由表（nginx 路径匹配），字典字符串索引都有使用到这种数据结构。 

### Geospatial 地理空间 （不常用）
存储和操作地理空间位置信息的数据结构，地理空间位置就是经度和纬度了，那么其作用在：存储一个或多个经纬度坐标（经度, 纬度），并快速地根据用户给定的位置，找出其附近一定范围内的其他地点。其特点可以用于以下场景（可以作为轻量级解决方案，专业的还是需要 gis 数据库 PostGIS）：
- 附近的人/地点： 这是最经典的应用。比如微信/滴滴/美团/Uber 中查找附近的用户、商家、车辆。
- 签到打卡： 用户在某地签到，判断签到位置是否在有效范围内（如公司、活动现场）。
- 地理位置信息流： 只展示用户所在城市或附近发生的新闻、动态。
- 物流与配送： 实时追踪快递员、外卖员位置，分配最近的订单。
- 物联网 (IoT)： 追踪设备（如共享单车、资产追踪器）的位置。

### bitmap 
其本身不是一个独立的数据结构，是 string 类型的结构利用。将一个 String 值当作一个由一系列比特位（0 或 1）组成的巨大数组来操作。 它非常适合用来处理海量的、与用户ID或日期相关的布尔值标记和统计问题。当你遇到“是/否”、“有/无”、“真/假”这类二元状态，并且数据量巨大时，第一个就应该想到它。
- 用户签到/打卡： 极度节省空间。
- 用户活跃度统计： 每天用一个 Bitmap，每一位代表一个用户是否活跃。可以轻松计算每日活跃用户(DAU)、每月活跃用户(MAU)，以及用户留存率（通过 BITOP AND 计算两天都活跃的用户）。
- 布隆过滤器 (Bloom Filter)： Bitmap 是实现布隆过滤器的基础数据结构，用于高效地判断一个元素是否一定不存在或可能存在于一个超大集合中，常用于缓存穿透解决方案。
- 特征开关/权限控制： 每一位可以代表一个特定的功能开关或权限。一个用户的全部权限可以用一个 Bitmap 表示，检查权限就是 GETBIT 操作。
- 实时数据同步： 标记哪些数据发生了变更，需要被同步。

使用场景的样例：
- 传统方法（用 Set/String）：
  - 如果一年用一条 String，存储 user:1001:2023 "110110...0"，需要 365 字节。
  - 如果每天用一个 KV，SETBIT user:1001:2023:day:1 1，需要 365 个键，每个键即使只存 1 bit，Redis 也有元数据开销，总空间更大。

- Bitmap 方法：
  - SETBIT user:1001:2023 100 1 // 在第 100 天签到
  - 只需要 1 个 Key！365 天大约需要 365 / 8 ≈ 46 字节。存储 1000 万用户的签到情况，总数据量也才 1000w * 46 bytes ≈ 460 MB。

### bitfields
这个数据结构有点强大，而且设计的很巧妙。我把它理解成一个使用 bit 位来表达数据结构的一种类型。比如如果传统的我们要表达以下内容：
用户id，用户余额，年龄，登陆次数，是否登陆。以上这些信息我们会采用 json string 或者存在 关系型数据库的中。但 redis 给了一种新方式存取这些数据结构，它采用位表达。 比如以下这种方式：
```
| 字段名 | 类型 | 偏移量 | 位宽 | 说明 |
| ：--- | :--- | :--- | :--- | :--- |
| logged_in | u1 | 0 | 1 bit | 是否登录 (0 或 1) |
| login_count | u4 | 1 | 4 bits | 今日登录次数 (0-15) |
| age | u7 | 5 | 7 bits | 年龄 (0-127) |
| balance | i16 | 12 | 16 bits | 账户余额（有符号，-32768 到 32767) |
| user_id | u32 | 28 | 32 bits | 用户ID |
```
可以用于存储用户状态和游戏角色的多种属性和状态
### Probabilistic 概率数据结构
它们通过引入一定的误差来换取存储空间和计算效率的显著提升。这类数据结构特别适合处理海量数据。即如果数据量小的情况下这些功能可能不没有太多的效果，但是到了一定数据量级别后，这个数据结构就非常有用且划算。其主要包含以下数据结构：
- bloom filter：成员查询（是否存在）。如 某个健是否存在，爬虫的 url 去重
- HyperLogLog： 基数估计（统计不重复元素）误差大约是 0.8%，如 统计网站用户活跃度-DAU, 需要统计成千上万个维度（不同页面、不同活动）的UV来说，传统方式完全不可行，而HLL可以轻松应对。非常节省内存
- Count-Min Sketch：频率估计（统计元素出现次数），
- Top-K：找出频繁项（例如热门话题、热销商品）。
因此可以特别适合以下这些场景：
- 大数据和流处理：实时分析数据流，如统计独立访问用户（UV）、最频繁出现的元素等1。 HyperLogLog
- 数据库系统：快速判断键是否存在，避免不必要的磁盘查找（如LSM树中的SSTable使用布隆过滤器）1。 bloomfliter
- 网络和分布式系统：用于网络路由、缓存同步、重复数据检测等。
- 监控和性能分析：例如使用t-digest来估算应用延迟的分位数（如P99延迟）。
- 网络爬虫：判断URL是否已被爬取过。bloomfliter
- 安全领域：用于恶意网站或垃圾邮件的初步过滤。 bloomfliter
- 热点排名：Count-Min Sketch/Top-K

### timeseries 时序性数据
这个数据结构有很多数据库支持，比如 elasticsearch, prometheus,influxdb 等，其中 prometheus,influxdb 是专门针对这种时序性数据类型支持的数据库， 其有以下特点：
- at-most-once 只会投递一次最多一次
- 消息不会持久化，重启会丢失
因此其可以用在允许消息丢失的场景下：比如广播消息，事件通知 这种地方
## 高可用架构
基本上数据库的高可用架构都是 2 种解决方案：
- 主从复制模式 （pgsql，mysql，redis）
- 数据分片 （es，minio）
主从的架构也可以进一步分库，对不同的数据要求进行分库集群，把不同的数据放到不通的主从集群中。很多场景 redis 可以采用
- 主从复制模式 + 分表分库集群，
- 哨兵模式，需要奇数，配置合理参数，防止脑裂

### 主从模式
主节点负责写操作，从节点异步复制主节点数据。读写分离，主节点宕机需要手动切换，异步复制存在数据丢失的可能。
### 哨兵模式（Sentinel）
可以理解在主从的结构上面增加一层服务，用于监控节点是否健康（透过心跳极值）等。一组 Sentinel 进程（推荐至少 3 个）监控 Redis 主从集群，当发现主节点不可用时，自动执行 故障转移（Failover）。Sentinel 定期发送心跳，确认主从是否健康。Sentinel 通过 Raft 类似的投票机制选出新的主节点。

Redis Sentinel 模式下，脑裂主要由网络分区导致，会出现两个主节点。
处理方式包括：
- 利用 Sentinel 的多数投票机制（至少 3 个节点，避免少数派误判）。
- 配置 min-slaves-to-write 和 min-slaves-max-lag，让孤立主节点拒绝写入。
- 客户端通过 Sentinel 获取主节点地址，避免继续写旧主。
- 在更严格场景，可以结合 Keepalived 或外部仲裁组件进一步降低风险。

### cluster 模式
数据按照 **哈希槽（hash slot, 共 16384 个）**分片存储到多个节点，每个分片有 1 个主节点 + N 个从节点，写入时根据 key 的哈希值定位到对应的 slot → 再路由到对应主节点，从节点作为备份，主节点挂了后会由从节点自动顶上，集群内节点通过 Gossip 协议互相通信，检测健康状态。
- 不支持多 key 跨分片事务（只能在相同 slot 内）。

### 第三方方案（生产中常见）
- Keepalived + VIP（虚拟 IP）：Keepalived 监控 Redis 主节点，主挂了后切 VIP 到从节点
- Codis / Twemproxy / Nutcracker：代理层做分片，后端 Redis 节点负责存储

## 使用场景
- 缓存：利用 string，hash 等数量类型缓存数据，配置：ttl 过期和 lur 淘汰策略
- 会话存储：Web 登录状态（SessionID → 用户信息），分布式应用共享登录状态（Spring Session + Redis）。
- 计数器 / 排行榜： 视频播放数、文章点赞数，在线人数统计。游戏积分排行榜（ZSET）。
- 消息队列：
    - List：简单队列（LPUSH + RPOP）。
    - Pub/Sub：订阅发布模型，实时推送。
    - Stream：支持消息确认、消费组，类似 Kafka。
- 分布式锁：利用 Redis 的 SETNX（set if not exists）+ 过期时间实现互斥锁。
```
RedLock 算法
```
- 限流：Redis 的原子操作和 TTL 实现接口限流
    - 固定窗口计数（INCR + EXPIRE）。
    - 滑动窗口 / 漏桶 / 令牌桶算法。

- 延时队列 / 任务调度
    - 利用 ZSET 的有序特性（score = 时间戳），可以实现延时任务。
    
- 地理位置（Geo）应用：利用 redis Geospatial 地理空间的数据结构可以支持支持存储地理坐标并做范围查询
    - 附近的人 / 附近的店。
    - 打车软件查找附近的司机。
- 位图（Bitmap）：利用二进制位存储/统计数据，节省空间。百万级数据存储只需几 MB 内存。
    - 用户签到（1 表示签到，0 表示未签到）
    - 活跃用户统计（某天哪些用户登录过）

- 布隆过滤器（Bloom Filter）： 借助 Redis 模块（RedisBloom），用来快速判断元素是否存在（有一定误判率）
    - 黑名单校验
    - 过滤无效请求（如避免缓存穿透）

## 其他拓展
### SETNX vs REDLOCK
SETNX 锁： 通过 SETNX key value + ttl 实现分布式过期时间锁。其实现非常的简单，单个节点就可以使用，因此会存在以下缺点：
1. 单节点故障，导致死锁
2. 过期的问题，存在业务还未完成，但是锁已经释放
3. 可靠性问题，高可用或分布式 Redis 集群下容易出现“脑裂”或锁丢失。如当主节点宕机，新节点没有此 key 则会导致获取到锁，另外脑裂的情况下，导致客户端也能获取到锁。

redlock：
1. 部署 N 个独立 Redis 实例（推荐 5 个）。
2. 客户端尝试在每个实例上获取锁（SET key value NX PX ttl）。
3. 如果超过一半的实例成功获取 → 锁获取成功。
4. 锁超时或失败 → 释放已获取的锁，重试。
5. 释放锁：必须在自己持有的锁上删除（检查 value），保证安全。
因为其特点对网络依赖大，并且只要一半获取锁即成功，因此是非强一致性，cap 理论中偏 ap，因此 redlock 可以用于 业务高并发、允许偶尔失败的场景，比如：
- 缓存更新、限流、秒杀抢购锁、短时互斥操作
如果对强一致性要求高的需要选择 etcd 和 consul ， zookeeper 这种 
