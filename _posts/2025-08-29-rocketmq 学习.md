---
title: rocketmq 学习
author: 刘Sir
date: 2025-08-28 10:10:00 +0800
categories: [技术]
tags: [redis]
render_with_liquid: false
---

## 顺序消息保证
1. 订单/交易系统：用户下单 → 扣减库存 → 生成支付记录。同一业务相关的消息，可以保证按发送顺序被消费
2. 高可靠性： 交易系统不能丢消息，
    -  消息写入磁盘才算成功
    -  Master-Slave 或多副本复制，不丢消息
    -  事务消息：可以保证消息与业务操作一致性（事务半消息 + commit/rollback）
3. 延时消息/定时消息
    - 支付超时自动关闭订单
    - 延迟通知用户或库存恢复
4. 高吞吐 & 高可用
    - RocketMQ 设计基于 分区队列 + 异步复制
    - 支持高吞吐量的消息写入和消费
    - Master-Slave 自动切换
5. 事物消息（解决本地事务与消息不一致的问题）
    - 下单 → 扣库存 → 生成支付记录，需要原子性
    - Producer 发送半消息
    - 根据业务结果提交或回滚消息

## 事物消息
https://rocketmq.apache.org/docs/featureBehavior/04transactionmessage
**mq 的事务消息只是保证本地事物和消息发送一起成功，或者一起失败，并不是跨服务的分布式事物**
在使用 mq 的过程中，生产者和 mq 之间是通过网络传递的，网络传递就具有不完全可靠性。比如有很重要的消息一定要发送到 mq 中让其可以消费，但是因为网络我们没办法保证我们的消息一定能投递到 mq 中，比如：我们业务下单后需要投递消息到 mq 的列子，业务代码可以保证本地事物（下单）成功，但无法保证一定能投递到 mq。以往我们要解决这个问题需要业务记录投递记录表，定时扫描 + 人工补偿。那么现在 rocket mq 通过这样一个事物机制帮助我们实现了自动处理这个过程。其实现的方式关键是有 3 个地方：
1. 消息半提交：生产者第一次和 mq 通信是 half-messge （ mq 不会投递到消费 ）
2. 本地事物：本地事物提交成功/失败 告诉 mq，commit/rollback
3. 事物回查机制：在 2 的场景下，也可能发生网络问题，mq 就会通过回查生产者的事物状态（间隔时间，回查次数）
本地事物的状态只用业务自己清楚，因此我们需要增加一个回调（callback），监听（listener）也好让 mq 回查的时返回对应的事物状态。其实这里还是无法完全保证，因为如果超过回查的次数就可能不会回查了，half message 会被丢弃。因此为了更多的保证像这种场景下业务方还是需要记录一个事物消息状态表进行兜底，另外要监控 mq 的日志中 half-message 丢弃的日志，及时感知异常消息。

## tcp 拥塞控制
网络中的路由器、链路等资源被过多的数据占满，导致 丢包、延迟增加、带宽利用率下降，tcp 处理拥塞的方式：
- 慢启动：利用拥塞窗口 vwnd，初始窗口 cwnd=1mss，小于 ssthresh 指数增长。（很像慢慢试探，慢慢加大窗口值。而不是一开始就冲）
- 拥塞避免：当 cwnd >= ssthresh，到达这个阈值后，变成线性增长，避免速度过快
- 快重传：三个重复的 ACK，不等超时，立刻重传丢失的包
- 快恢复：丢包后，重新评估 cwnd 的值，降低速度
就是根据 tcp 链路中的实时状态（丢包，ack，延迟）等情况，实时调整链路的速度。

## rocketmq 的组件和作用
- broker：核心组件，负责消息的存储（commitlog + 索引），转发，过滤，回查。
- nameserver：服务发现和路由管理，无状态的，多节点部署，互不通信，保证高可用
- controller（5.0 版本开始引入）：负责Broker 主从选举 和 元数据管理，raft 协议，3 个节点以上（kafka zookeeper）
- proxy：5.0 后引入，在 broker 和 客户端中增加的一层，多租户和 Serverless 场景

可以看出 rocket mq 组件多，架构较为复杂。从 5.0 版本后引入 controller 解决主从自动切换，额外再引入 proxy 组件放到 broker 前，屏蔽 broker 细节，使得 rocket mq 架构更复杂。但是总体的高可用还是基于 broker 的主从复制（异步和同步），实际上在我的角度看来既然引入了 proxy 在前，那么 broker 的主从架构其实可以变成多主架构，数据在主主之间复制整体的架构会更简洁。这里可能是基于历史的原因：RocketMQ 的底层存储引擎是 CommitLog + ConsumeQueue，它本质是“单点顺序写”设计，多主写会破坏这个模型。要改的话几乎等于重写存储层。 另外 RocketMQ：追求 事务一致性、低延迟、金融级可靠，不容许随意丢失/乱序