---
title: 换轮胎记
author: 刘Sir
date: 2025-08-28 10:10:00 +0800
categories: [技术]
tags: [redis]
render_with_liquid: false
---

# 基础题
## Redis 的数据结构有哪些？你能举例说明在什么场景下会用到 Hash 和 ZSet 吗？
- String：最基础的类型，适合存储计数器、Session、分布式锁。
- Hash：键值对集合，小数据量用 ziplist，大数据量用 hashtable，适合存储对象缓存，比如用户信息。
- List：双向链表，可以做简单消息队列、任务列表。
- Set：无序去重集合，适合标签、共同好友等场景。
- ZSet：有序集合，底层是 skiplist + hash table，适合做排行榜、延时队列。
- Stream：Redis 5.0 引入的消息队列，支持消费组。
- Bitmap / HyperLogLog：适合做状态标记、UV 统计

## Redis 的单线程模型是如何实现高性能的？
- 单线程 Reactor 模型：命令执行在单线程中完成，避免了多线程的上下文切换和锁竞争。
- IO 多路复用：通过 epoll/kqueue 等机制同时处理大量客户端连接，非阻塞 IO。
- 内存存储，避免磁盘开销
- 高效的数据结构优化。skiplist，hashtable，ziplist
- 后台子进程/线程辅助：AOF 重写、RDB 持久化、异步删除等由额外线程处理，不阻塞主线程。

但是也有劣势，因为所有的命令执行都在单个线程中排队执行，当某个名字执行耗时操作后，会导致堵塞后面的命令，并且导致读写事件数据过多。从而可能会出现以下情况：
- socket buffer 会积压，导致客户端的写操作变慢，甚至触发 TCP 的 backpressure（阻塞写入）
- 客户端读写延迟
- 拒绝连接
- OOM

优化做法：
- 限制慢命令：在文档里明确标注了危险命令（KEYS、FLUSHALL、SMEMBERS 大集合）。
- 渐进式处理：比如 SCAN 代替 KEYS，UNLINK 代替 DEL，避免一次性阻塞。
- 分库，集群

此处顺便了解下 tcp socket buffer 和 backpresure
### tcp socket buffer
当一个进程（比如 Redis）使用 TCP 通信时，内核会给每个 socket 分配两块缓冲区：
- 发送缓冲区（send buffer）：存放应用程序写入、但尚未被内核 TCP 协议栈发送出去的数据。比如 write(fd, "hello")，数据其实先进入 send buffer，之后再由 TCP 协议栈分片发送。
- 接收缓冲区（recv buffer）：存放内核接收到、但应用程序还没读取的数据。比如客户端发送请求到 Redis，数据先到内核 recv buffer，等 Redis 主线程调用 read() 时才取走。

buffer 的大小是有限的（通常几 KB ~ MB，/proc/sys/net/core/rmem_max、wmem_max 可以调）。那么再此基础上就延伸到 backpresure 机制
### tcp backpresure 反压机制
当生产数据的速度 > 消费数据的速度，就会出现 数据积压 > 反过来影响生产数据的速度 （反压）
- 应用写 send buffer → buffer 满了 → write() 阻塞/报错（EAGAIN）
- 应用没及时 read → recv buffer 满了 → TCP 不再 ack 新包 → 对方发送速率下降

通俗点理解：tcp 通信中客户端读的慢，会导致服务端写也回变慢。服务端读慢会导致客户端写慢。

## Redis 支持 RDB 和 AOF 两种持久化方式，它们各自的特点是什么？各自适合什么场景？如果同时开启，会发生什么情况？
rdb: 内存快照，fork 子进程执行，替换原 rdb 文件，因为 fork 是父进程的内存快照，因此这里会导致 2 倍内存使用，并且在子进程操作 rdb 的过程中，父进程会继续执行 copy-on-write 机制，写数据的时候会复制内存页，在新的内存页中写入新数据，也会导致内存上升。另外重要的一点内存快照方式存在 父子进程的数据不一致，在宕机的情况下存在丢失数据的风险。
aof（appendfsync）： 日志追加，redis 会把写名字以追加的方式写入文件，并且会随着文件大小进行重写（merge 相同命令），在重启后，通过读取命令恢复数据。丢失数据的可能性大大的减少。

rdb：适合读多，数据一致性要求不高的场景。
aof：适合写多，数据一致性要求高的场景。

同时开启可以有效的防止数据丢失，但是需要主要内存的配置，合理设置 ttl 和 lru 淘汰策略

## Redis 的过期策略有哪些？它们会带来什么影响？
- 惰性删除：只有访问 key 时才检查它是否过期（如一直不访问则一直滞留在内存中，增加内存负担）
- 定期收集：定期收集 key 检查是否过期 （取决于定期时间和采样，不会立刻删除）
- lfu： 内部维护 key 的访问频率，淘汰频率低（maxmemory-policy）
- lru： 内部维护 key 的最近访问时间，淘汰冷数据（maxmemory-policy）
```
# 在所有键中，淘汰使用频率最低的键
maxmemory-policy allkeys-lfu

# 仅在设置了过期时间的键中，淘汰使用频率最低的键
maxmemory-policy volatile-lfu
```
## 什么是 缓存击穿 / 缓存穿透 / 缓存雪崩？如何解决？
- 缓存击穿：数据不在缓存中（淘汰，回收），请求会直接到数据库（mysql），导致数据库压力增大
    - 数据预热：提前加载到缓存中
    - 无过期策略
    - 加锁
- 缓存穿透：数据不在缓存和数据库中，但是查询还是会一直打到数据库上，导致数据库压力大
    - 过滤（bloomfilter）
    - 设置默认值
    - 增加请求校验
- 缓存雪崩：数据不在缓存中，请求打到数据库后导致数据库宕机，再导致缓存宕机。
    - 过期时间加随机值（避免同一时间大面积过期
    - 热点数据永不过期（逻辑过期 + 后台异步刷新）
    - 多级缓存（本地缓存 + Redis + CDN）
    - 降级限流（DB 被打爆时快速失败，返回兜底数据）
# 工程实践题
## 如果你的 Redis 实例内存持续上升，你会如何排查？
1. 先确认是业务数据增长还是非业务性堆积
2. 再逐类排查：慢命令 / 写入突增 / 淘汰策略 / fork 内存膨胀 / 缓冲区积压
3. 最后给解决方案：限流 + TTL + 淘汰策略 + 客户端缓冲限制

慢命令排查：MONITOR / SLOWLOG get 看慢命令 -》 优化命令，避免 HGETALL，KEYS 等命令
写入突增：DBSIZE / SCAN 看 key 总量是否突增。 -》 配置 ttl，maxmemory 策略
淘汰策略：Redis 默认是 noeviction，CONFIG GET maxmemory-policy -》 配置合适的策略
内存碎片 & fork 内存膨胀（copy-on-write）：INFO memory（mem_fragmentation_ratio > 1.5）碎片严重，合理调度 rdb/aof 重写，避免高峰期触发
缓冲区积压（pub/sub  stream）：
- pub/sub： 实时推送，不会堆积内存，但是会导致 socket buffer 堆积，
- stream： 默认是内存队列，rdb/aof 也会使它持久化到磁盘
## 在高并发写入的场景下，如何保证 Redis 的数据和数据库的一致性？
redis 定位是内存型缓存数据库，不具备数据库的事物特性，因此数据强一致性无法完全做到。但我们可以采用最终一致性的方案，让他们数据一致：
1. 先写数据库，在写 redis
2. mq 异步更新redis
3. binlog （canal）同步
4. 代码定期对账 + 补偿（手动/程序）


